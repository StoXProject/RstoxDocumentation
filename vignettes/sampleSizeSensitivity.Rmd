---
title: "Analysis of Sample Size Sensitivity"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Analysis of Sample Size Sensitivity}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(RstoxDocumentation)
```

This is a short introduction to using StoX to investigate if a sampling program tend to over-sample. That is, if data is collected well beyond points of diminishing returns with respect to precision of estimates. For a fruitful analysis, one has to first identify all estimated parameters of interest. There are usually some parameters that are estimated that are of little significance. For instance abundance or mean weight of minor age-groups. If these are not identified up front, and all available computations are produced, one can be almost certain in identifying some parameter that has too low precision. Conversely, all parameters of interest must be checked. Acceptable precision of mean weight, does not imply that one will have acceptable precision abundance, and vice verca. Acceptable precision for big domains (e.g. all fish in an entiry fishery), does not at all imply acceptable precision in specific age-groups for specific gears, etc.

The analysis is here exemplified to fisheries sampling with samples from the catch lottery. But the general framework can be adapted to any StoX project that produce estimates and estimates of uncertainty.

## Analysis

The analysis runs a real estimate for real data, but mimics reduced sampling by randomly removing samples. If measures of uncertainty (e.g. CV) is not sensitive to removal of a large number of samples, we should consider if the fishery may be over-sampled.

The function defined below executes a StoX project, but inserts in the execution a function that manipulates the output of a process. That function will be defined to mimic reduced sampling. It also delegate reporting to a function yet to be defined:

```{r}
#' Executes stox project with inserted data manipulation routine
#' @param project
#' @param dataProcess Name of process in baseline, whose data output should be manipulated by 'reductionFunction'
#' @param n argument to reductionFunction, the number of samples to remove
#' @param reductionFunction function that accepts and returns the output from dataProcess, and, and the argument n 
#' @param reportFunction function that accepts what is returned from RstoxFramework::runProject, and extracts desired results as a data.table
#' @return the data returned from 'resultProcess'
runWithReducedData <- function(project, dataProcess, n, reductionFunction=reductionBySelectionProb, reportFunction=report){
  p <- RstoxFramework::runProject(project, modelNames="baseline", endProcess = dataProcess)
  data <- p[[dataProcess]]
  reducedData <- reductionFunction(data, n)
  
  replaceDataList <- list()
  replaceDataList[[dataProcess]] <- reducedData

  
  result <- RstoxFramework::runProject(project, startProcess = dataProcess, replaceDataList = replaceDataList)
  return(reportFunction(result))
}
```

I will the define the function that mimics reduction in samples. For this example, the easiest way is to manipulate the output of the assignment of PSUs to data, so this function accepts and returns data of type PSUSamplingParametersData. For other kinds of estimation, selection is not treated separately from recording of data, and the most natural way to implement data reduction would be something similar that accepts and returns StoxBioticData. The following function reduces the sample size by 'n', and keeps data with probability proportional to the selection probabilities.

```{r}
reductionBySelectionProb <- function(PSUSamplingParametersData, n){
  
  N <- nrow(PSUSamplingParametersData$SelectionTable)
  stopifnot(n<N)
  keep <- N-n
  
  selection <- PSUSamplingParametersData
  selection$SelectionTable <- selection$SelectionTable[sample.int(nrow(PSUSamplingParametersData$SelectionTable), keep, prob = PSUSamplingParametersData$SelectionTable$SelectionProbability),]
  selection$SampleTable$n <- keep

  return(selection)  
}
```

Finally, the following function extract the results we are interested in from a modified StoX-process run:

```{r}
report <- function(projectResult){
  return(projectResult[["ReportCaa"]]$NbyAge)
}
```


Below is an example executing the three functions defined above, and comparing the run with the original data with a run with a random reduction of 10 PSUs (hauls):

```{r}
exampleProject <- system.file("resources", "analyticalCAA", package = "RstoxDocumentation")
regularResult <- runWithReducedData(exampleProject, "AssignPSUSamplingParameters", 0, function(x,y){x})
reducedResult <- runWithReducedData(exampleProject, "AssignPSUSamplingParameters", 10)
comparison <- merge(regularResult, reducedResult, by=c("AgeGroup", "Age"), suffix=c(".regular", ".reduced"))
comparison
```

Check for warnings and messages in the output above, as these will be turned off in the repeated simulation below:

I then define a function that runs this project repeatedly, with varying number of removed samples. It also adds some information to the reported output (number of removed samples, and and identifier for each replicate):

```{r sensitivity, message=FALSE}
sampleSensitivity <- function(project, dataProcess="AssignPSUSamplingParameters", maxRemove=40, replications=1){
  
  result <- NULL
  
  computations <- maxRemove*replications
  for (i in 1:maxRemove){
    for (j in 1:replications){
      reducedResult <- runWithReducedData(project, dataProcess, i)
      reducedResult$sampleReduction <- i
      reducedResult$replicate <- j
      
      result <- rbind(result, reducedResult)
    }
  }
  return(result)
}
res<-suppressWarnings(suppressMessages(sampleSensitivity(exampleProject)))
```

Assuming that the abundance of age group is of interest, plotting the CV of catch at age estimates does provide any clear indication of oversampling:

```{r}
ggplot2::ggplot(res) + ggplot2::geom_line(ggplot2::aes(x=sampleReduction, y=SD/CatchAtAge, col=AgeGroup)) + ggplot2::ylim(c(0,.5))
```

