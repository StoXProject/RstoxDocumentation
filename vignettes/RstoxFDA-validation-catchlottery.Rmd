---
title: "Validation of catch lottery estimation with RstoxFDA"
output: rmarkdown::html_vignette
author: Edvin Fuglebakk
vignette: >
  %\VignetteIndexEntry{Validation of catch lottery estimation with RstoxFDA}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(RstoxDocumentation)
library(survey)
iterations <- 1000 # the number of iterations to run for simulations
```

# Catch lottery estimation with RstoxFDA
RstoxFDA provides functions for analytical estimates for multi-stage unequal probability sampling. This vignette provides analysis to corroborate its correctness with respect to estimation for sampling with the Catch lottery.

## Data
Validation will be based on example data bundled with the RstoxFDA package. This contains data sets for the North Sea Herring (NSH) fisheries in 2022:
* RstoxFDA::CatchLotteryExample: NSH biological records from samples for the 2022 fishery
* RstoxFDA::CatchLotterySamplingExample: Sampling probabilites for the NSH vessels selected for sampling in 2022 fishery 
* RstoxFDA::CatchLotteryLandingExample: NSH landings from Norwegian vessels larger than 15 m in 2022.

## Workflows
I will test the correctness of a workflow implementing a design based estimate of abundance, mean length and mean weight in age-groups, using RstoxFDA. The workflow implements analaysis for a simple desgin, with only one strata and no PSU-domains. The workflow is defined below:

```{r design-based-estimate}
designBased <- function(records, sampling, MeanOfMeans=F){
  #Define sampling parameters within haul for individual fish
  indParameters <- RstoxFDA::DefineIndividualSamplingParameters(StoxBioticData = records, 
                                                                DefinitionMethod = "SRS", 
                                                                Parameters=c("IndividualSex", "IndividualAge"))
  
  #Assign selection to data
  PSUassigment = RstoxFDA::AssignPSUSamplingParameters(DefinitionMethod="MissingAtRandom", 
                                                       StoxBioticData=records, 
                                                       PSUSamplingParametersData=sampling, 
                                                       SamplingUnitId="serialnumber", 
                                                       DataRecordId="Haul")
  #Estimate for each haul
  psuEstimates <- RstoxFDA::AnalyticalPSUEstimate(StoxBioticData=records, 
                                                  IndividualSamplingParametersData = indParameters,
                                                  DomainVariables=c("IndividualAge"), 
                                                  Variables=c("IndividualRoundWeight", "IndividualTotalLength"))
  #Estimate for the population / sampling frame
  populationEstimates = RstoxFDA::AnalyticalPopulationEstimate(PSUassigment, 
                                                             AnalyticalPSUEstimateData = psuEstimates,
                                                             MeanOfMeans = MeanOfMeans)
  
  #reformat data
  length <- populationEstimates$Variables[Variable=="IndividualTotalLength",]
  length$IndividualTotalLength <- length$Mean
  lengthVar <- populationEstimates$VariablesCovariance[Variable1=="IndividualTotalLength" & Variable2=="IndividualTotalLength" & Domain1==Domain2,]
  lengthVar$se.IndividualTotalLength <- sqrt(lengthVar$MeanCovariance)
  lengthVar$Domain <- lengthVar$Domain1
  weight <- populationEstimates$Variables[Variable=="IndividualRoundWeight",]
  weight$IndividualRoundWeight <- weight$Mean
  weight$TotalRoundWeight <- weight$Total
  weightVar <- populationEstimates$VariablesCovariance[Variable1=="IndividualRoundWeight" & Variable2=="IndividualRoundWeight" & Domain1==Domain2,]
  weightVar$Domain <- weightVar$Domain1
  weightVar$se.IndividualRoundWeight <- sqrt(weightVar$MeanCovariance)
  weightVar$se.TotalRoundWeight <- sqrt(weightVar$TotalCovariance)
  abundance <- populationEstimates$Abundance
  abundanceVar <- populationEstimates$AbundanceCovariance[Domain1==Domain2,]
  abundanceVar$se.Abundance <- sqrt(abundanceVar$AbundanceCovariance)
  abundanceVar$Domain <- abundanceVar$Domain1

  result <- merge(populationEstimates$StratificationVariables, length[,.SD,.SDcol=c("Stratum", "Domain", "IndividualTotalLength")])
  result <- merge(result, populationEstimates$DomainVariables, by="Domain")
  result <- merge(result, abundance[,.SD,.SDcol=c("Stratum", "Domain", "Abundance")])
  result <- merge(result, abundanceVar[,.SD,.SDcol=c("Stratum", "Domain", "se.Abundance")])
  result <- merge(result, weight[,.SD,.SDcol=c("Stratum", "Domain", "IndividualRoundWeight", "TotalRoundWeight")], by=c("Stratum", "Domain"))
  result <- merge(result, lengthVar[,.SD,.SDcol=c("Stratum", "Domain", "se.IndividualTotalLength")], by=c("Stratum", "Domain"))
  result <- merge(result, weightVar[,.SD,.SDcol=c("Stratum", "Domain", "se.IndividualRoundWeight","se.TotalRoundWeight")], by=c("Stratum", "Domain"))
  
  result$Age <- as.character(result$IndividualAge)
  result$Age[is.na(result$Age)] <- "NA"
  result$cv.Abundance <- result$se.Abundance / result$Abundance
  result <- result[,.SD,.SDcol=c("Age", "Abundance", "se.Abundance", "cv.Abundance", "TotalRoundWeight", "IndividualRoundWeight", "IndividualTotalLength", "se.TotalRoundWeight", "se.IndividualRoundWeight", "se.IndividualTotalLength")]
  return(result)
}
```

## Comparison with other estimators
Lumleys survey-package provides analytical design based estimators for unequal probability sampling. It does not provide the Hansen-Hurwtiz variance estimator implemented in RstoxFDA, but allows the same kind of sampling weights (based on selection probabilities), and variance estimates are expected to be similar. I implement an estimator for the desing below:

```{r designBasedLumley}
#HT estimate with the survey package
designBasedLumley <- function(records, sampling){
  
  # format data
  indRecords <- RstoxData::MergeStoxBiotic(records)
  indRecords <- merge(indRecords, sampling$SelectionTable, by.x="serialnumber", by.y="SamplingUnitId")
  indRecords <- indRecords[!is.na(indRecords$IndividualAge) | !is.na(indRecords$IndividualSex),]
  indRecords$Age <- as.character(indRecords$IndividualAge)
  indRecords$Age[is.na(indRecords$Age)] <- "NA"
  indRecords$Age <- as.factor(indRecords$Age)
  
  sampled <- indRecords[,list(Sampled=.N),by="serialnumber"]
  indRecords <- merge(indRecords, sampled, all.x=T)
  
  indRecords$SampleSel <- 1 / (indRecords$CatchFractionNumber / indRecords$Sampled)

  design <- survey::svydesign(~serialnumber+Sample, probs = ~SelectionProbability+SampleSel, variables = ~Age+IndividualRoundWeight+IndividualTotalLength, data=indRecords)
  
  result <- survey::svyby(~IndividualRoundWeight+IndividualTotalLength, ~Age, design, survey::svymean)
  
  return(result)
}

```

Comparing the estimators for the example data shows total agreement for mean estimates, and similar magnitudes for error estimates:

```{r compWithLumley}
sampling <- RstoxFDA::CatchLotterySamplingExample
sampling$SelectionTable <- sampling$SelectionTable[!is.na(sampling$SelectionTable$SelectionProbability),]
resRstoxFDA <- designBased(RstoxFDA::CatchLotteryExample, sampling)
resLumley <- designBasedLumley(RstoxFDA::CatchLotteryExample, sampling)

comp <- merge(resRstoxFDA[,.SD, .SDcol=c("Age", "IndividualRoundWeight", "IndividualTotalLength", "se.IndividualRoundWeight", "se.IndividualTotalLength")], resLumley, by="Age", suffixes = c("-RstoxFDA", "-Lumley"))
comp <- comp[,.SD,.SDcols = c("Age", "IndividualRoundWeight-Lumley", "IndividualRoundWeight-RstoxFDA", "se.IndividualRoundWeight-Lumley", "se.IndividualRoundWeight-RstoxFDA")]

stopifnot(all(abs(comp$`IndividualRoundWeight-Lumley`-comp$`IndividualRoundWeight-RstoxFDA`)<1e-6))

comp
```

## Simulation

I will corroborate that the estimators have expected properties by a simulation study. I will construct a pseudo-population from the example data-set, so that population means and totals are known, and simulate sampling and estimation to investigate bias.

### Pseudo-population

I will define a pseudo-population that is simply a replication of the example data set, including only fish with observed Age, length and weight, and including only sampled hauls. I will represent this with the original data set, and and ordered list of replicated haul-ids (serialnumbers) and for each of them an ordered list of replicated fish-ids.

```{r pseudopop}
#Define pseudopopulation
serialnumbers <- RstoxFDA::CatchLotteryExample$Haul$serialnumber
indtable <- RstoxData::MergeStoxBiotic(RstoxFDA::CatchLotteryExample)
indtable <- indtable[!is.na(indtable$IndividualAge) & !is.na(indtable$IndividualTotalLength) & !is.na(indtable$IndividualRoundWeight),]
indtable$haulreplications <- ceiling(RstoxFDA::CatchLotterySamplingExample$SampleTable$N / length(serialnumbers))
indtable$fishreplications <- 0
haulPopulation <- rep(serialnumbers, unique(indtable$haulreplications))
fish <- list()
for (s in serialnumbers){
  individuals <- indtable$Individual[indtable$serialnumber == s]
  haulsize <- unique(indtable$CatchFractionNumber[indtable$serialnumber == s])
  fr <- ceiling(haulsize / length(individuals))
  indtable$fishreplications[indtable$serialnumber==s] <- fr
  fish[[s]] <- rep(individuals, fr)
}

```

I define a function to compute population statitstics to compare with estimators. I include an option to make a total estimate (no age domains). For simplicity this is implemented as forcing all age groups to the age group "1":

```{r poplationStats}

#calculate population stats
getPopStats <- function(domain=T){
  tab <- indtable
  if (!domain){
    tab$IndividualAge <- 1
  }
populationStats <- tab[,list(Abundance=sum(fishreplications*haulreplications), 
                                  Weight=sum(IndividualRoundWeight*fishreplications*haulreplications),
                                  Length=sum(IndividualTotalLength*fishreplications*haulreplications)), by="IndividualAge"]
populationStats$MeanWeight <- populationStats$Weight / populationStats$Abundance
populationStats$MeanLength <- populationStats$Length / populationStats$Abundance
populationStats <- populationStats[order(populationStats$IndividualAge),]
populationStats$Age <- as.character(populationStats$IndividualAge)  

return(populationStats)
}

```


I will assign a fixed set of sampling probabilites that will be used for all simulations:

```{r selectionProbabilities}
SelectionProbabilities <- RstoxFDA::CatchLotterySamplingExample$SelectionTable$SelectionProbability[
  match(haulPopulation, RstoxFDA::CatchLotterySamplingExample$SelectionTable$SamplingUnitId)]
SelectionProbabilities <- SelectionProbabilities/sum(SelectionProbabilities)
```

### Virtual sampling

I will then define a function that performs Poisson sampling from this population, mimicking the catch lottery. The function will construct the data sets necessary for estimation:

```{r sampling}

samplePseudoPop <- function(expSampleSize=80){

  InclusionProbabilites <- 1-((1-SelectionProbabilities)**expSampleSize)
    
  selection <- runif(length(haulPopulation)) <= InclusionProbabilites
  haulSelection <- haulPopulation[selection]

  pseudoserialnumbers <- 1:length(haulSelection)

  #construct sampling parameters
  sp <- RstoxFDA::CatchLotterySamplingExample
  sp$SampleTable$N <- length(haulPopulation)
  sp$SampleTable$n <- length(haulSelection)
  sp$SelectionTable <- sp$SelectionTable[match(haulSelection, sp$SelectionTable$SamplingUnitId),]
  sp$SelectionTable$SelectionProbability <- SelectionProbabilities[match(sp$SelectionTable$SamplingUnitId, haulPopulation)]
  sp$SelectionTable$InclusionProbability <- InclusionProbabilites[match(sp$SelectionTable$SamplingUnitId, haulPopulation)]
  sp$SelectionTable$HHsamplingWeight <- 1 / (sp$SelectionTable$SelectionProbability * sum(1/sp$SelectionTable$SelectionProbability))
  sp$SelectionTable$HTsamplingWeight <- 1 / (sp$SelectionTable$InclusionProbability * sum(1/sp$SelectionTable$InclusionProbability))
  sp$SelectionTable$SamplingUnitId <- pseudoserialnumbers
  
  #construct sample data from pseudopopulation
  records <- list()
  records$Cruise <- rbind(records$Cruise, 
                        indtable[!duplicated(indtable$Cruise),.SD,.SDcol=names(RstoxFDA::CatchLotteryExample$Cruise)])

  for (pseudoserialnumber in pseudoserialnumbers){
      h <- haulSelection[pseudoserialnumber]
      ind <- indtable[serialnumber == h,] #select haul
      ind <- ind[sample.int(nrow(ind),nrow(ind), replace = T),] #resample fish
      ind$IndividualKey <- 1:nrow(ind)
    
      stopifnot(length(unique(ind$CruiseKey))==1)
      stopifnot(length(unique(ind$StationKey))==1)
      stopifnot(length(unique(ind$HaulKey))==1)
      stopifnot(length(unique(ind$SampleKey))==1)
      stopifnot(length(unique(ind$SpeciesCategoryKey))==1)
      stopifnot(all(!duplicated(ind$IndividualKey)))

      ind$StationKey <- pseudoserialnumber      
      ind$HaulKey <- pseudoserialnumber
      ind$serialnumber <- pseudoserialnumber

      records$Station <- rbind(records$Station,
                        ind[!duplicated(ind$Station),.SD,.SDcol=names(RstoxFDA::CatchLotteryExample$Station)] )
      records$Haul <- rbind(records$Haul,
                        ind[!duplicated(ind$Haul),.SD,.SDcol=names(RstoxFDA::CatchLotteryExample$Haul)])
      records$SpeciesCategory <- rbind(records$SpeciesCategory,
                        ind[!duplicated(ind$SpeciesCategory),.SD,.SDcol=names(RstoxFDA::CatchLotteryExample$SpeciesCategory)])
      records$Sample <- rbind(records$Sample,
                        ind[!duplicated(Sample),.SD,.SDcol=names(RstoxFDA::CatchLotteryExample$Sample)])
      records$Individual <- rbind(records$Individual,
                        ind[,.SD,.SDcol=names(RstoxFDA::CatchLotteryExample$Individual)])

  }
  
  #fix identifiers
  records$Haul$Haul <- paste(records$Haul$CruiseKey, 
                            records$Haul$StationKey, 
                            records$Haul$HaulKey, sep="-")
  records$SpeciesCategory$SpeciesCategory <- records$SpeciesCategory$SpeciesCategoryKey
  records$Sample$Sample <- paste(records$Sample$CruiseKey, 
                                records$Sample$StationKey, 
                                records$Sample$HaulKey, 
                                records$Sample$SpeciesCategoryKey, 
                                records$Sample$SampleKey, sep="-")
  records$Individual$Individual <- paste(records$Individual$CruiseKey, 
                                records$Individual$StationKey, 
                                records$Individual$HaulKey, 
                                records$Individual$SpeciesCategoryKey, 
                                records$Individual$SampleKey, 
                                records$Individual$IndividualKey, sep="-")
  
  output <- list()
  output$samplingParameters <- sp
  output$dataRecords <- records
  
  return(output)
}
```

I then have a known population, and a controlled selection from that population. So I can calculate known errors and compare to estimated errors. E.g.

```{r simulationExample}
sample <- samplePseudoPop()
estimate <- designBased(sample$dataRecords, sample$samplingParameters)
comp <- merge(estimate, getPopStats(), by="Age", suffix=c(".estimate", ".pop"))
comp$abundance.error <- comp$Abundance.estimate - comp$Abundance.pop
comp$MeanWeight.error <- comp$IndividualRoundWeight - comp$MeanWeight
comp$se.Abundance
comp$se.IndividualRoundWeight
comp[,c("Age", "abundance.error", "se.Abundance", "MeanWeight.error", "se.IndividualRoundWeight")]
```
For unbiased estimation of parameters and their variance, I would expect:
* The mean error over simulations to be zero. That is bias is 0. I will compute the relative bias: mean(estimate-truth)/truth
* The mean se over simulations to be equal to the mean absolute error over simulations. That is biasSE is zero. I will compute the relative biasSE (mean(se) - mean(abs(estimate-truth))) / truth.

Note that the mean true error is not known in the same way that the error of individual estimates are known. Rather it is estimated over simulations, and compared to the average estimate of SE. the relative biasSE is not relative to the true error, but to the total true value.

### Estimation statistics

I set up the simulation and calculate cumulative bias and biasSE, so that I can monitor convergence of the statistics. I make the domain estimate by age optional, forcing everythin to be age 1, when the domain estimate is not desired:

```{r simulate}
simulate <- function(iterations=1000, n=80, domain=T){
  
  simStats <- NULL
  populationStats <- getPopStats(domain)
  
  for (i in 1:iterations){
    sample <- samplePseudoPop(n)
    if (!domain){
      sample$dataRecords$Individual$IndividualAge=1
    }
    estimate <- designBased(sample$dataRecords, sample$samplingParameters)
    comp <- merge(estimate, populationStats, by="Age", suffix=c(".estimate", ".pop"))
    abundanceStats <- comp[,list(iteration=i, Param="Abundance", truth=Abundance.pop, estimate=Abundance.estimate, se=se.Abundance), by="Age"]
    totalWeightStats <- comp[,list(iteration=i, Param="TotalWeight", truth=Weight, estimate=TotalRoundWeight, se=se.TotalRoundWeight), by="Age"]
    meanWeightStats <- comp[,list(iteration=i, Param="MeanWeight", truth=MeanWeight, estimate=IndividualRoundWeight, se=se.IndividualRoundWeight), by="Age"]
    
    simStats <- rbind(simStats, abundanceStats)
    simStats <- rbind(simStats, meanWeightStats)
    simStats <- rbind(simStats, totalWeightStats)
  }
  
  simStats <- simStats[order(simStats$iteration),]
  
  simSummary <- simStats[,list(iteration=iteration, error=estimate-truth, SE=se, bias=cumsum(estimate-truth)/iteration, relativeBias=(cumsum(estimate-truth)/iteration)/unique(truth), biasSE=cumsum(se)/iteration - cumsum(estimate-truth)/iteration, relativeBiasSE=(cumsum(se)/iteration - cumsum(abs(estimate-truth))/iteration) / unique(truth)), by=c("Param", "Age")]
  
  return(simSummary)
}

```

I simulate estimation of totals, without age domains. The estimators should theoretically be unbiased for this estimation:

```{r simNoDomains}
timestampStart <- Sys.time()
simStatsNoDomains <- simulate(iterations, domain=F)
timestampEnd <- Sys.time()
difftime(timestampEnd, timestampStart)
```

I also simulate estimation of totals within domains. These are ratio estimators, and some bias is to be expected:

```{r simDomains}
timestampStart <- Sys.time()
simStatsAgeDomains <- simulate(iterations, domain=T)
timestampEnd <- Sys.time()
difftime(timestampEnd, timestampStart)
```

### Results unbiased estimators

For the simulation of the unbiased estimators, the simulation confirms the theoretical expectation, corroborating that the implementation is correct. For point estimates (Less than 0.1 % relative bias):

```{r resultNoDomainsPointEstimates}
minX<-floor(iterations/3)
ggplot2::ggplot(simStatsNoDomains[Param=="Abundance" & iteration>minX,]) + ggplot2::geom_line(ggplot2::aes(x=iteration, y=relativeBias, col=Age)) + ggplot2::ggtitle("Relative bias abundance")
ggplot2::ggplot(simStatsNoDomains[Param=="MeanWeight" & iteration>minX,]) + ggplot2::geom_line(ggplot2::aes(x=iteration, y=relativeBias, col=Age)) + ggplot2::ggtitle("Relative bias mean weight")
ggplot2::ggplot(simStatsNoDomains[Param=="TotalWeight" & iteration>minX,]) + ggplot2::geom_line(ggplot2::aes(x=iteration, y=relativeBias, col=Age)) + ggplot2::ggtitle("Relative bias total weight")
stopifnot(all(abs(simStatsNoDomains$relativeBias[simStatsNoDomains$iteration==max(simStatsNoDomains$iteration)])<1e-3))
```

and for error estimates (less than 0.1 % relative bias):

```{r resultsNoDomainsError Estimates}
ggplot2::ggplot(simStatsNoDomains[Param=="Abundance" & iteration>minX,]) + ggplot2::geom_line(ggplot2::aes(x=iteration, y=relativeBiasSE, col=Age)) + ggplot2::ggtitle("Relative bias SE abundance")
ggplot2::ggplot(simStatsNoDomains[Param=="MeanWeight" & iteration>minX,]) + ggplot2::geom_line(ggplot2::aes(x=iteration, y=relativeBiasSE, col=Age)) + ggplot2::ggtitle("Relative bias SE mean weight")
ggplot2::ggplot(simStatsNoDomains[Param=="TotalWeight" & iteration>minX,]) + ggplot2::geom_line(ggplot2::aes(x=iteration, y=relativeBiasSE, col=Age)) + ggplot2::ggtitle("Relative bias SE total weight")
stopifnot(all(abs(simStatsNoDomains$relativeBiasSE[simStatsNoDomains$iteration==max(simStatsNoDomains$iteration)])<1e-3))
```

### Results ratio estimators

As expected, the ratio estimators for domains exhibit a small bias. For point estimates, these are less than 5% for this example:

```{r resultsDomainsPointEstimates}
minX<-floor(iterations/3)
ggplot2::ggplot(simStatsAgeDomains[Param=="Abundance" & iteration>minX,]) + ggplot2::geom_line(ggplot2::aes(x=iteration, y=relativeBias, col=Age)) + ggplot2::ggtitle("Relative bias abundance")
ggplot2::ggplot(simStatsAgeDomains[Param=="MeanWeight" & iteration>minX,]) + ggplot2::geom_line(ggplot2::aes(x=iteration, y=relativeBias, col=Age)) + ggplot2::ggtitle("Relative bias mean weight")
ggplot2::ggplot(simStatsAgeDomains[Param=="TotalWeight" & iteration>minX,]) + ggplot2::geom_line(ggplot2::aes(x=iteration, y=relativeBias, col=Age)) + ggplot2::ggtitle("Relative bias total weight")
stopifnot(all(abs(simStatsAgeDomains$relativeBias[simStatsAgeDomains$iteration==max(simStatsAgeDomains$iteration)])<.05))
```
For the error estimates, it is a bit higher, with worst case performance less 15% for this example:

```{r resultsDomainsErrorEstimates}
ggplot2::ggplot(simStatsAgeDomains[Param=="Abundance" & iteration>minX,]) + ggplot2::geom_line(ggplot2::aes(x=iteration, y=relativeBiasSE, col=Age)) + ggplot2::ggtitle("Relative bias SE abundance")
ggplot2::ggplot(simStatsAgeDomains[Param=="MeanWeight" & iteration>minX,]) + ggplot2::geom_line(ggplot2::aes(x=iteration, y=relativeBiasSE, col=Age)) + ggplot2::ggtitle("Relative bias SE mean weight")
ggplot2::ggplot(simStatsAgeDomains[Param=="TotalWeight" & iteration>minX,]) + ggplot2::geom_line(ggplot2::aes(x=iteration, y=relativeBiasSE, col=Age)) + ggplot2::ggtitle("Relative bias SE total weight")
stopifnot(all(abs(simStatsAgeDomains$relativeBiasSE[simStatsAgeDomains$iteration==max(simStatsAgeDomains$iteration)])<.15))
```
The performance of the estimator for domains is expected to be better for high abundance domains:

```{r biasVsAbdunance}
finalStats <- simStatsAgeDomains[simStatsAgeDomains$iteration==max(simStatsAgeDomains$iteration)]
finalStats <- merge(finalStats, getPopStats(T), by="Age")
ggplot2::ggplot(finalStats) + ggplot2::geom_point(ggplot2::aes(x=Abundance, y=relativeBias, col=Param)) + ggplot2::ggtitle("relative bias point estimates")
ggplot2::ggplot(finalStats) + ggplot2::geom_point(ggplot2::aes(x=Abundance, y=relativeBiasSE, col=Param)) + ggplot2::ggtitle("relative bias error estimates")
```
