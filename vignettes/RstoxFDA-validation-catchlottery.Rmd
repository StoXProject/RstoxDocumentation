---
title: "Validation of catch lottery estimation with RstoxFDA"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Validation of catch lottery estimation with RstoxFDA}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(RstoxDocumentation)
```

# Catch lottery estimation with RstoxFDA
RstoxFDA provides functions for analytical estimates for multi-stage unequal probability sampling. This vignette provides analysis to corroborate its correctness with respect to estimation for sampling with the Catch lottery.

## Data
Validation will be based on example data bundled with the RstoxFDA package. This contains data sets for the North Sea Herring (NSH) fisheries in 2022:
* RstoxFDA::CatchLotteryExample: NSH biological records from samples for the 2022 fishery
* RstoxFDA::CatchLotterySamplingExample: Sampling probabilites for the NSH vessels selected for sampling in 2022 fishery 
* RstoxFDA::CatchLotteryLandingExample: NSH landings from Norwegian vessels larger than 15 m in 2022.

## Workflows
We will test the correctness of two workflows: A design based estimate of abundance, mean length and mean weight in age-groups, and a ratio estimate of the same. The workflows will be defined by the following functions:

Design based:
```{r design-based-estimate}
designBased <- function(records, sampling, MeanOfMeans=F){
  #Define sampling parameters within haul for individual fish
  indParameters <- RstoxFDA::DefineIndividualSamplingParameters(StoxBioticData = records, 
                                                                DefinitionMethod = "SRS", 
                                                                Parameters=c("IndividualSex", "IndividualAge"))
  
  #Assign selection to data
  PSUassigment = RstoxFDA::AssignPSUSamplingParameters(DefinitionMethod="MissingAtRandom", 
                                                       StoxBioticData=records, 
                                                       PSUSamplingParametersData=sampling, 
                                                       SamplingUnitId="serialnumber", 
                                                       DataRecordId="Haul")
  #Estimate for each haul
  psuEstimates <- RstoxFDA::AnalyticalPSUEstimate(StoxBioticData=records, 
                                                  IndividualSamplingParametersData = indParameters,
                                                  DomainVariables=c("IndividualAge"), 
                                                  Variables=c("IndividualRoundWeight", "IndividualTotalLength"))
  #Estimate for the population / sampling frame
  populationEstimates = RstoxFDA::AnalyticalPopulationEstimate(PSUassigment, 
                                                             AnalyticalPSUEstimateData = psuEstimates,
                                                             MeanOfMeans = MeanOfMeans)
  
  #reformat data
  length <- populationEstimates$Variables[Variable=="IndividualTotalLength",]
  length$IndividualTotalLength <- length$Mean
  lengthVar <- populationEstimates$VariablesCovariance[Variable1=="IndividualTotalLength" & Variable2=="IndividualTotalLength" & Domain1==Domain2,]
  lengthVar$se.IndividualTotalLength <- sqrt(lengthVar$MeanCovariance)
  lengthVar$Domain <- lengthVar$Domain1
  weight <- populationEstimates$Variables[Variable=="IndividualRoundWeight",]
  weight$IndividualRoundWeight <- weight$Mean
  weight$TotalRoundWeight <- weight$Total
  weightVar <- populationEstimates$VariablesCovariance[Variable1=="IndividualRoundWeight" & Variable2=="IndividualRoundWeight" & Domain1==Domain2,]
  weightVar$Domain <- weightVar$Domain1
  weightVar$se.IndividualRoundWeight <- sqrt(weightVar$MeanCovariance)
  weightVar$se.TotalRoundWeight <- sqrt(weightVar$TotalCovariance)
  abundance <- populationEstimates$Abundance
  abundanceVar <- populationEstimates$AbundanceCovariance[Domain1==Domain2,]
  abundanceVar$se.Abundance <- sqrt(abundanceVar$AbundanceCovariance)
  abundanceVar$Domain <- abundanceVar$Domain1

  result <- merge(populationEstimates$StratificationVariables, length[,.SD,.SDcol=c("Stratum", "Domain", "IndividualTotalLength")])
  result <- merge(result, populationEstimates$DomainVariables, by="Domain")
  result <- merge(result, abundance[,.SD,.SDcol=c("Stratum", "Domain", "Abundance")])
  result <- merge(result, abundanceVar[,.SD,.SDcol=c("Stratum", "Domain", "se.Abundance")])
  result <- merge(result, weight[,.SD,.SDcol=c("Stratum", "Domain", "IndividualRoundWeight", "TotalRoundWeight")], by=c("Stratum", "Domain"))
  result <- merge(result, lengthVar[,.SD,.SDcol=c("Stratum", "Domain", "se.IndividualTotalLength")], by=c("Stratum", "Domain"))
  result <- merge(result, weightVar[,.SD,.SDcol=c("Stratum", "Domain", "se.IndividualRoundWeight","se.TotalRoundWeight")], by=c("Stratum", "Domain"))
  
  result$Age <- as.character(result$IndividualAge)
  result$Age[is.na(result$Age)] <- "NA"
  result$cv.Abundance <- result$se.Abundance / result$Abundance
  result <- result[,.SD,.SDcol=c("Age", "Abundance", "se.Abundance", "cv.Abundance", "TotalRoundWeight", "IndividualRoundWeight", "IndividualTotalLength", "se.TotalRoundWeight", "se.IndividualRoundWeight", "se.IndividualTotalLength")]
  return(result)
}
```

Ratio estimate:
```{r ratio-estimate}
ratioEstimate <- function(records, sampling, landings){
  
}
```


## Comparison with other estimators
```{r designBasedLumley}
#HT estimate with the survey package
designBasedLumley <- function(records, sampling){
  
  # format data
  indRecords <- RstoxData::MergeStoxBiotic(records)
  indRecords <- merge(indRecords, sampling$SelectionTable, by.x="serialnumber", by.y="SamplingUnitId")
  indRecords <- indRecords[!is.na(indRecords$IndividualAge) | !is.na(indRecords$IndividualSex),]
  indRecords$Age <- as.character(indRecords$IndividualAge)
  indRecords$Age[is.na(indRecords$Age)] <- "NA"
  indRecords$Age <- as.factor(indRecords$Age)
  
  sampled <- indRecords[,list(Sampled=.N),by="serialnumber"]
  indRecords <- merge(indRecords, sampled, all.x=T)
  
  indRecords$SampleSel <- 1 / (indRecords$CatchFractionNumber / indRecords$Sampled)

  design <- survey::svydesign(~serialnumber+Sample, probs = ~SelectionProbability+SampleSel, variables = ~Age+IndividualRoundWeight+IndividualTotalLength, data=indRecords)
  
  result <- survey::svyby(~IndividualRoundWeight+IndividualTotalLength, ~Age, design, survey::svymean)
  
  return(result)
}

```


```{r}
sampling <- RstoxFDA::CatchLotterySamplingExample
sampling$SelectionTable <- sampling$SelectionTable[!is.na(sampling$SelectionTable$SelectionProbability),]
resRstoxFDA <- designBased(RstoxFDA::CatchLotteryExample, sampling)
resLumley <- designBasedLumley(RstoxFDA::CatchLotteryExample, sampling)

comp <- merge(resRstoxFDA[,.SD, .SDcol=c("Age", "IndividualRoundWeight", "IndividualTotalLength", "se.IndividualRoundWeight", "se.IndividualTotalLength")], resLumley, by="Age", suffixes = c("-RstoxFDA", "-Lumley"))
comp <- comp[,.SD,.SDcols = c("Age", sort(names(comp)[names(comp)!="Age"]))]
comp
```

## Simulation

We will corroborate that the estimators have expected properties by a simulation study. We will construct a pseud-population from the example data-set, so that population means and totals are known, and simulate sampling and estimation to investigate bias.

### Pseudo-population

We will define a pseudo-population that is simply a replication of the example data set, including only fish with observed Age, length and weight, and including only sampled hauls. We will represent this with the original data set, and and ordered list of replicated haul-ids (serialnumbers) and for each of them an ordered list of replicated fish-ids.

```{r pseudopop}
#Define pseudopopulation
serialnumbers <- RstoxFDA::CatchLotteryExample$Haul$serialnumber
indtable <- RstoxData::MergeStoxBiotic(RstoxFDA::CatchLotteryExample)
indtable <- indtable[!is.na(indtable$IndividualAge) & !is.na(indtable$IndividualTotalLength) & !is.na(indtable$IndividualRoundWeight),]
indtable$haulreplications <- ceiling(RstoxFDA::CatchLotterySamplingExample$SampleTable$N / length(serialnumbers))
indtable$fishreplications <- 0
haulPopulation <- rep(serialnumbers, unique(indtable$haulreplications))
fish <- list()
for (s in serialnumbers){
  individuals <- indtable$Individual[indtable$serialnumber == s]
  haulsize <- unique(indtable$CatchFractionNumber[indtable$serialnumber == s])
  fr <- ceiling(haulsize / length(individuals))
  indtable$fishreplications[indtable$serialnumber==s] <- fr
  fish[[s]] <- rep(individuals, fr)
}

#calculate population stats
populationStats <- indtable[,list(Abundance=sum(fishreplications*haulreplications), 
                                  Weight=sum(IndividualRoundWeight*fishreplications*haulreplications),
                                  Length=sum(IndividualTotalLength*fishreplications*haulreplications)), by="IndividualAge"]
populationStats$MeanWeight <- populationStats$Weight / populationStats$Abundance
populationStats$MeanLength <- populationStats$Length / populationStats$Abundance
populationStats <- populationStats[order(populationStats$IndividualAge),]
populationStats$Age <- as.character(populationStats$IndividualAge)
```

We will assign a fixed set of sampling probabilites that will be used for all simulations:

```{r selectionProbabilities}
SelectionProbabilities <- RstoxFDA::CatchLotterySamplingExample$SelectionTable$SelectionProbability[
  match(haulPopulation, RstoxFDA::CatchLotterySamplingExample$SelectionTable$SamplingUnitId)]
SelectionProbabilities <- SelectionProbabilities/sum(SelectionProbabilities)
```

We will then define a function that performs Poisson sampling from this population, mimicking the catch lottery. The function will construct the data sets necessary for estimation:

```{r sampling}

samplePseudoPop <- function(expSampleSize=80){

  InclusionProbabilites <- 1-((1-SelectionProbabilities)**expSampleSize)
    
  selection <- runif(length(haulPopulation)) <= InclusionProbabilites
  haulSelection <- haulPopulation[selection]

  pseudoserialnumbers <- 1:length(haulSelection)

  #construct sampling parameters
  sp <- RstoxFDA::CatchLotterySamplingExample
  sp$SampleTable$N <- length(haulPopulation)
  sp$SampleTable$n <- length(haulSelection)
  sp$SelectionTable <- sp$SelectionTable[match(haulSelection, sp$SelectionTable$SamplingUnitId),]
  sp$SelectionTable$SelectionProbability <- SelectionProbabilities[match(sp$SelectionTable$SamplingUnitId, haulPopulation)]
  sp$SelectionTable$InclusionProbability <- InclusionProbabilites[match(sp$SelectionTable$SamplingUnitId, haulPopulation)]
  sp$SelectionTable$HHsamplingWeight <- 1 / (sp$SelectionTable$SelectionProbability * sum(1/sp$SelectionTable$SelectionProbability))
  sp$SelectionTable$HTsamplingWeight <- 1 / (sp$SelectionTable$InclusionProbability * sum(1/sp$SelectionTable$InclusionProbability))
  sp$SelectionTable$SamplingUnitId <- pseudoserialnumbers
  
  #construct sample data from pseudopopulation
  records <- list()
  records$Cruise <- rbind(records$Cruise, 
                        indtable[!duplicated(indtable$Cruise),.SD,.SDcol=names(RstoxFDA::CatchLotteryExample$Cruise)])

  for (pseudoserialnumber in pseudoserialnumbers){
      h <- haulSelection[pseudoserialnumber]
      ind <- indtable[serialnumber == h,] #select haul
      ind <- ind[sample.int(nrow(ind),nrow(ind), replace = T),] #resample fish
      ind$IndividualKey <- 1:nrow(ind)
    
      stopifnot(length(unique(ind$CruiseKey))==1)
      stopifnot(length(unique(ind$StationKey))==1)
      stopifnot(length(unique(ind$HaulKey))==1)
      stopifnot(length(unique(ind$SampleKey))==1)
      stopifnot(length(unique(ind$SpeciesCategoryKey))==1)
      stopifnot(all(!duplicated(ind$IndividualKey)))

      ind$StationKey <- pseudoserialnumber      
      ind$HaulKey <- pseudoserialnumber
      ind$serialnumber <- pseudoserialnumber

      records$Station <- rbind(records$Station,
                        ind[!duplicated(ind$Station),.SD,.SDcol=names(RstoxFDA::CatchLotteryExample$Station)] )
      records$Haul <- rbind(records$Haul,
                        ind[!duplicated(ind$Haul),.SD,.SDcol=names(RstoxFDA::CatchLotteryExample$Haul)])
      records$SpeciesCategory <- rbind(records$SpeciesCategory,
                        ind[!duplicated(ind$SpeciesCategory),.SD,.SDcol=names(RstoxFDA::CatchLotteryExample$SpeciesCategory)])
      records$Sample <- rbind(records$Sample,
                        ind[!duplicated(Sample),.SD,.SDcol=names(RstoxFDA::CatchLotteryExample$Sample)])
      records$Individual <- rbind(records$Individual,
                        ind[,.SD,.SDcol=names(RstoxFDA::CatchLotteryExample$Individual)])

  }
  
  #fix identifiers
  records$Haul$Haul <- paste(records$Haul$CruiseKey, 
                            records$Haul$StationKey, 
                            records$Haul$HaulKey, sep="-")
  records$SpeciesCategory$SpeciesCategory <- records$SpeciesCategory$SpeciesCategoryKey
  records$Sample$Sample <- paste(records$Sample$CruiseKey, 
                                records$Sample$StationKey, 
                                records$Sample$HaulKey, 
                                records$Sample$SpeciesCategoryKey, 
                                records$Sample$SampleKey, sep="-")
  records$Individual$Individual <- paste(records$Individual$CruiseKey, 
                                records$Individual$StationKey, 
                                records$Individual$HaulKey, 
                                records$Individual$SpeciesCategoryKey, 
                                records$Individual$SampleKey, 
                                records$Individual$IndividualKey, sep="-")
  
  output <- list()
  output$samplingParameters <- sp
  output$dataRecords <- records
  
  return(output)
}
```

We then have a known population, and a controlled selection from that population. So we can calculate known errors and compare to estimated errors. E.g.

```{r simulationExample}
sample <- samplePseudoPop()
estimate <- designBased(sample$dataRecords, sample$samplingParameters)
comp <- merge(estimate, populationStats, by="Age", suffix=c(".estimate", ".pop"))
comp$abundance.error <- comp$Abundance.estimate - comp$Abundance.pop
comp$MeanWeight.error <- comp$IndividualRoundWeight - comp$MeanWeight
comp$se.Abundance
comp$se.IndividualRoundWeight
comp[,c("Age", "abundance.error", "se.Abundance", "MeanWeight.error", "se.IndividualRoundWeight")]
```
For unbiased estimation of parameters and their variance, we would expect:
* The mean error over simulations to be zero. That is bias is 0.
* The mean se over simulations to be equal to the mean absolute error over simulations. That is biasSE is zero.

We set up the simulation and calculate cumulative bias and biasSE, so that we can monitor convergence of the statistics.

```{r simulate}
simulate <- function(iterations=1000, n=80){
  
  simStats <- NULL
  
  for (i in 1:iterations){
    sample <- samplePseudoPop(n)
    estimate <- designBased(sample$dataRecords, sample$samplingParameters)
    comp <- merge(estimate, populationStats, by="Age", suffix=c(".estimate", ".pop"))
    abundanceStats <- comp[,list(iteration=i, Param="Abundance", truth=Abundance.pop, estimate=Abundance.estimate, se=se.Abundance), by="Age"]
    meanWeightStats <- comp[,list(iteration=i, Param="MeanWeight", truth=MeanWeight, estimate=IndividualRoundWeight, se=se.IndividualRoundWeight), by="Age"]
    
    simStats <- rbind(simStats, abundanceStats)
    simStats <- rbind(simStats, meanWeightStats)
  }
  
  simStats <- simStats[order(simStats$iteration),]
  
  simSummary <- simStats[,list(iteration=iteration, error=estimate-truth, SE=se, bias=cumsum(estimate-truth)/iteration, relativeBias=(cumsum(estimate-truth)/iteration)/unique(truth), biasSE=cumsum(se)/iteration - cumsum(estimate-truth)/iteration, relativeBiasSE=(cumsum(se)/iteration - cumsum(abs(estimate-truth))/iteration) / (cumsum(abs(estimate-truth))/iteration)), by=c("Param", "Age")]
  
  return(simSummary)
}
iterations <- 1000
timestampStart <- Sys.time()
simStats <- simulate(iterations)
timestampEnd <- Sys.time()
difftime(timestampEnd, timestampStart)
```

```{r}
minX<-floor(iterations/3)
ggplot2::ggplot(simStats[Param=="Abundance" & iteration>minX,]) + ggplot2::geom_line(ggplot2::aes(x=iteration, y=relativeBias, col=Age)) + ggplot2::ggtitle("Relative bias abundance")
ggplot2::ggplot(simStats[Param=="MeanWeight" & iteration>minX,]) + ggplot2::geom_line(ggplot2::aes(x=iteration, y=relativeBias, col=Age)) + ggplot2::ggtitle("Relative bias mean weight")
ggplot2::ggplot(simStats[Param=="Abundance" & iteration>minX,]) + ggplot2::geom_line(ggplot2::aes(x=iteration, y=relativeBiasSE, col=Age)) + ggplot2::ggtitle("Relative bias SE abundance")
ggplot2::ggplot(simStats[Param=="MeanWeight" & iteration>minX,]) + ggplot2::geom_line(ggplot2::aes(x=iteration, y=relativeBiasSE, col=Age)) + ggplot2::ggtitle("Relative bias SE mean weight")
```



## Notes
* Implement simulation for MeanOfMeans and !MeanOfMeans
* May drop the comparison with Lumley when simulation is implemented. Or change it to a HH weighting and compare only means.
* write tutorial on MeanOfMeans vs !MeanOfMeans. Contrast mean weight in age group with something with uglier distribution of means e.g. mean abundance in age group. Perhaps put in RstoxFDA.
